{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6456da1e",
   "metadata": {},
   "source": [
    "Credits/Course URL - https://www.udemy.com/course/the-ultimate-beginners-guide-to-natural-language-processing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f1dfe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import random\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from langdetect import detect\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from slugify import slugify, Slugify\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04697103",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666734f",
   "metadata": {},
   "source": [
    "#### Reading the data and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b5d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(r'E:\\Github\\Datasets\\tweets.csv', \n",
    "                     low_memory=False, \n",
    "                     encoding = 'latin1', \n",
    "                     header=None,\n",
    "                     names=['sentiment', 'id', 'date', 'query', 'user', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac879de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33a4970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   sentiment  1600000 non-null  int64 \n",
      " 1   id         1600000 non-null  int64 \n",
      " 2   date       1600000 non-null  object\n",
      " 3   query      1600000 non-null  object\n",
      " 4   user       1600000 non-null  object\n",
      " 5   text       1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efdd7dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "4    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a00783b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_processed = tweets.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f015f2df",
   "metadata": {},
   "source": [
    "#### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a313c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_processed = tweets_processed.drop(['id', 'date', 'query', 'user'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be2f185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "124b392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = tweets_processed['text'].values\n",
    "y_ = tweets_processed['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "880a9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_, y, y_ = train_test_split(X_, y_, test_size=0.90, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26416171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000,), (160000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "546c51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70eba78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120000,), (120000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8617801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000,), (40000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88817055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 4], dtype=int64), array([59903, 60097], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af243d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 4], dtype=int64), array([20132, 19868], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59657e9b",
   "metadata": {},
   "source": [
    "#### Detecting language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d81fb292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect('lets see which language is this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89ba6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_detector(sentence_list):\n",
    "    \n",
    "    lang_detected_list = []\n",
    "    \n",
    "    for index, tweet in enumerate(sentence_list):\n",
    "        try:\n",
    "            if len(tweet) != 0:\n",
    "                lang = detect(tweet)\n",
    "                lang_detected_list.append(lang)\n",
    "            else:\n",
    "                lang_detected_list.append('EMPTY TWEET')\n",
    "        except:\n",
    "            print(f\"Exception Encountered at position {index}: {tweet}\")        \n",
    "            lang_detected_list.append('UNKNOWN LANG : '+ str(tweet))\n",
    "            pass\n",
    "    return lang_detected_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88600c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Encountered at position 19075: Work@Amata \n",
      "Exception Encountered at position 38730: Sunday@Office .... \n",
      "Exception Encountered at position 91580:  lol@teedramoses\n"
     ]
    }
   ],
   "source": [
    "lang_X_train = lang_detector(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4111b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_X_test = lang_detector(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0cfd4",
   "metadata": {},
   "source": [
    "Checking how many unique languages got detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a2cc709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['UNKNOWN LANG :  lol@teedramoses',\n",
       "        'UNKNOWN LANG : Sunday@Office .... ', 'UNKNOWN LANG : Work@Amata ',\n",
       "        'af', 'ca', 'cs', 'cy', 'da', 'de', 'en', 'es', 'et', 'fi', 'fr',\n",
       "        'hr', 'hu', 'id', 'it', 'lt', 'lv', 'nl', 'no', 'pl', 'pt', 'ro',\n",
       "        'sk', 'sl', 'so', 'sq', 'sv', 'sw', 'tl', 'tr', 'uk', 'vi'],\n",
       "       dtype='<U34'),\n",
       " array([     1,      1,      1,   1184,    255,     58,    742,    243,\n",
       "           289, 111462,     85,    358,    193,    388,    103,     24,\n",
       "           420,    278,     19,      6,    581,    479,    154,    101,\n",
       "           116,     66,     66,   1016,     77,    233,    129,    681,\n",
       "           106,      2,     83], dtype=int64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lang_X_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d354e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['af', 'ca', 'cs', 'cy', 'da', 'de', 'en', 'es', 'et', 'fi', 'fr',\n",
       "        'hr', 'hu', 'id', 'it', 'lt', 'lv', 'nl', 'no', 'pl', 'pt', 'ro',\n",
       "        'sk', 'sl', 'so', 'sq', 'sv', 'sw', 'tl', 'tr', 'uk', 'vi'],\n",
       "       dtype='<U2'),\n",
       " array([  432,    87,    20,   235,    93,    94, 37183,    27,   101,\n",
       "           51,   106,    36,    13,   145,    81,     6,     2,   214,\n",
       "          136,    51,    28,    36,    17,    25,   367,    21,    91,\n",
       "           36,   214,    15,     1,    36], dtype=int64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lang_X_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d9a6634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_train</th>\n",
       "      <th>y_train</th>\n",
       "      <th>lang_X_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@la_bellachica Its Ok lol i feel so much bigge...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Daionii glasses are hot on girls</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't have the time 2 bike 2day. What a lousy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow, Â£155 for an administration charge.  And ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@TillyRossetti  i just had some too- but unfor...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             X_train  y_train lang_X_train\n",
       "0  @la_bellachica Its Ok lol i feel so much bigge...        4           en\n",
       "1                 @Daionii glasses are hot on girls         4           en\n",
       "2  Don't have the time 2 bike 2day. What a lousy ...        0           en\n",
       "3  Wow, Â£155 for an administration charge.  And ...        0           en\n",
       "4  @TillyRossetti  i just had some too- but unfor...        0           en"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df = pd.DataFrame({'X_train': X_train, 'y_train': y_train, 'lang_X_train': lang_X_train})\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6bf6b4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>lang_X_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@mattpicasso iPhone is doing that &amp;quot;not op...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@H4mTar0 Day of the Tentacle: briljant!</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who's that GIRL?? Livin' MY LIFE!!!!!!!!!!! I'...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tryna b a gud friend but i dunno if i can keep...</td>\n",
       "      <td>0</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Halliwellicious Ciao teso...  Come stai?</td>\n",
       "      <td>4</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              X_test  y_test lang_X_test\n",
       "0  @mattpicasso iPhone is doing that &quot;not op...       0          en\n",
       "1           @H4mTar0 Day of the Tentacle: briljant!        4          en\n",
       "2  Who's that GIRL?? Livin' MY LIFE!!!!!!!!!!! I'...       0          en\n",
       "3  tryna b a gud friend but i dunno if i can keep...       0          id\n",
       "4          @Halliwellicious Ciao teso...  Come stai?       4          it"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df = pd.DataFrame({'X_test': X_test, 'y_test': y_test, 'lang_X_test': lang_X_test})\n",
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5c724b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = X_train_df[X_train_df['lang_X_train'] == 'en']\n",
    "X_test_df = X_test_df[X_test_df['lang_X_test'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76b30009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@la_bellachica Its Ok lol i feel so much bigger than what i am! ugh when you gonna cook for me '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df['X_train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1cad196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whos that girl livin my life im soooo sad why i love u but i want him'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slugify(X_test_df['X_test'][2], to_lower = True, separator = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f42601c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_slugify = Slugify(to_lower = True, \n",
    "                         separator = ' ',\n",
    "                         safe_chars = '@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d06013c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@mattpicasso iphone is doing that quot not opening downloaded apps quot thing and i forgot my cord at home'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_slugify(X_test_df['X_test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e78e3268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lets try this @love myself party @ 31 dec 2022'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_slugify('lets try this @love myself party @ 31 Dec 2022!!!!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87760917",
   "metadata": {},
   "source": [
    "#### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bbad82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1cc06736fd0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ef33be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    \n",
    "    sentence = re.sub(r\"https?://[A-Za-z0-9/.-]+\", ' ', sentence) # Remove URLs\n",
    "    \n",
    "    custom_slugify = Slugify(to_lower = True, \n",
    "                         separator = ' ',\n",
    "                         safe_chars = '@')\n",
    "    \n",
    "    sentence = custom_slugify(sentence)\n",
    "    #sentence = sentence.lower()\n",
    "    sentence = re.sub(r\"@[A-Za-z0-9]+\", ' ', sentence)\n",
    "    \n",
    "    tokens = [token.text for token in nlp(sentence) if not (token.is_stop or token.like_num or token.is_punct or token.is_space or len(token) == 1)]\n",
    "    \n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7647272d",
   "metadata": {},
   "source": [
    "Testing preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e86aadcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awww bummer shoulda got david carr day'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing(\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  2 You shoulda got David Carr of Third Day to do it. ;D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85e027d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = [preprocessing(tweet) for tweet in X_train_df['X_train']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c031023",
   "metadata": {},
   "source": [
    "Randomly displaying 10 tweets after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "027611e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoping club shin stilts alas\n",
      "let good times roll\n",
      "try taking knives stabbing throat know feel right\n",
      "okay nt net connection updated organized freely organizers\n",
      "awww refreshing bath alternating hotncold water love feel water drops dancing eyelashes nosetip amp lipssss\n",
      "resist need asleep screwed tomorrow\n",
      "lost help find good home\n",
      "oh hot layin soon\n",
      "lmaoooo trice omg amp ur uncle\n",
      "great looking blog like use\n"
     ]
    }
   ],
   "source": [
    "for cnt in range(10):\n",
    "    print(X_train_cleaned[random.randint(0, len(X_train_cleaned)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47cd574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cleaned = [preprocessing(tweet) for tweet in X_test_df['X_test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a310d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waving alice goodbye\n",
      "yes night vanderpants essay wide awake ugh\n",
      "hope ai nt long ya\n",
      "miss nt\n",
      "know feeling sweet dreams\n",
      "chuckle drag hell pass creditor face damnation\n",
      "looking response start conversation\n",
      "hahaaaa doubt morning killed looooong time maybe weeks exercise mad\n",
      "going shower right ill yim love\n",
      "movie adorable pixar amp disney watch\n"
     ]
    }
   ],
   "source": [
    "for cnt in range(10):\n",
    "    print(X_test_cleaned[random.randint(0, len(X_test_cleaned)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "91f7791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = pd.Series(X_train_cleaned)\n",
    "X_test_cleaned = pd.Series(X_test_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "41358472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111462, 111462)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.shape[0], X_train_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1eba21ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37183, 37183)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.shape[0], X_test_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7e130731",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.concat([X_train_df.reset_index(drop=True), X_train_cleaned], axis = 1)\n",
    "X_train_df = X_train_df.rename(columns={0: 'X_train_cleaned'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9b322113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_train</th>\n",
       "      <th>y_train</th>\n",
       "      <th>lang_X_train</th>\n",
       "      <th>X_train_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111457</th>\n",
       "      <td>@Tinkerbell2009a Hi! I'm well thank you and yo...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>hi thank hope having good sunday far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111458</th>\n",
       "      <td>Tired from everything today. Had loads of fun ...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>tired today loads fun havta ready church</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111459</th>\n",
       "      <td>blahh well the bus s really cold today and I d...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>blahh bus cold today nt jacket haha people nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111460</th>\n",
       "      <td>Good morning everyone</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>good morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111461</th>\n",
       "      <td>@Shatran</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  X_train  y_train  \\\n",
       "111457  @Tinkerbell2009a Hi! I'm well thank you and yo...        4   \n",
       "111458  Tired from everything today. Had loads of fun ...        4   \n",
       "111459  blahh well the bus s really cold today and I d...        0   \n",
       "111460                             Good morning everyone         4   \n",
       "111461                                          @Shatran         4   \n",
       "\n",
       "       lang_X_train                                    X_train_cleaned  \n",
       "111457           en               hi thank hope having good sunday far  \n",
       "111458           en           tired today loads fun havta ready church  \n",
       "111459           en  blahh bus cold today nt jacket haha people nee...  \n",
       "111460           en                                       good morning  \n",
       "111461           en                                                     "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "12937edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.concat([X_test_df.reset_index(drop=True), X_test_cleaned], axis = 1)\n",
    "X_test_df = X_test_df.rename(columns={0: 'X_test_cleaned'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2f40d461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>lang_X_test</th>\n",
       "      <th>X_test_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37178</th>\n",
       "      <td>i'm sooo bored.  listening to some K-pop goodn...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>sooo bored listening pop goodness haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37179</th>\n",
       "      <td>@ExocetAU you have a cane?</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>cane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37180</th>\n",
       "      <td>@englishteach8  thanks for the follow Friday -...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>thanks follow friday saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37181</th>\n",
       "      <td>I hate Tuesdays....stupid update in progress.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>hate tuesdays stupid update progress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37182</th>\n",
       "      <td>On the road home. We discovered a dedicab SN2 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>road home discovered dedicab sn2 unlock code f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  X_test  y_test lang_X_test  \\\n",
       "37178  i'm sooo bored.  listening to some K-pop goodn...       0          en   \n",
       "37179                        @ExocetAU you have a cane?        4          en   \n",
       "37180  @englishteach8  thanks for the follow Friday -...       4          en   \n",
       "37181    I hate Tuesdays....stupid update in progress.         0          en   \n",
       "37182  On the road home. We discovered a dedicab SN2 ...       0          en   \n",
       "\n",
       "                                          X_test_cleaned  \n",
       "37178             sooo bored listening pop goodness haha  \n",
       "37179                                               cane  \n",
       "37180                      thanks follow friday saturday  \n",
       "37181               hate tuesdays stupid update progress  \n",
       "37182  road home discovered dedicab sn2 unlock code f...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e73e2ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.shape[0] == X_train_df['lang_X_train'].value_counts()['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "71e28790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.shape[0] == X_test_df['lang_X_test'].value_counts()['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b93ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cleaned_tweets_percent_train = round((sum(X_train_df['X_train_cleaned'] == '')/X_train_df.shape[0])*100,2)\n",
    "null_cleaned_tweets_percent_test = round((sum(X_test_df['X_test_cleaned'] == '')/X_test_df.shape[0])*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a28b0290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Percent having nothing after tweets are cleaned (of Training Data): 0.45%\n",
      "Data Percent having nothing after tweets are cleaned (of Testing Data): 0.41%\n"
     ]
    }
   ],
   "source": [
    "print(f'Data Percent having nothing after tweets are cleaned (of Training Data): {null_cleaned_tweets_percent_train}%')\n",
    "print(f'Data Percent having nothing after tweets are cleaned (of Testing Data): {null_cleaned_tweets_percent_test}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a35d0c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = X_train_df[X_train_df['X_train_cleaned'] != '']\n",
    "X_test_df = X_test_df[X_test_df['X_test_cleaned'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39eee6-615e-4515-bbfa-51f1946e71cc",
   "metadata": {},
   "source": [
    "#### Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned_concatd = ' '.join(X_train_cleaned)\n",
    "X_test_cleaned_concatd = ' '.join(X_test_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f90013-5cc1-4e22-b517-5a9919380bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud = WordCloud()\n",
    "word_cloud = word_cloud.generate(X_train_cleaned_concatd)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(word_cloud)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48330b37-c217-46f9-ab36-8d0a67e62632",
   "metadata": {},
   "source": [
    "### Detecting Laguages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a921d30-ffe1-4ea1-b914-3eec96b42816",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect('lets see which language is this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581ae95-8ddf-49a9-a996-df6eaa8867b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27f26d-7955-4652-8276-41b4bcce8a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b64e4-defa-4aa1-8321-18d08e8c0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentiment_classifier = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f863e7-95ce-4520-84a3-b6612c4fb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentiment_classifier.polarity_scores('I love India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578dc421-d570-475d-bd07-b2a191ad094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentiment_classifier.polarity_scores('I hate origano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940448cd-bc88-4775-a7e6-143146357931",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentiment_classifier.polarity_scores('I will got to market')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041b3f9-d410-42d0-8835-a8c2e1c11bc3",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48097e-f2b6-4b4f-a06c-3947456b5b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aef69b-207b-46cb-846e-f73f3804fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_cleaned[17775]\n",
    "del X_train_cleaned[79561]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e640f60-9e56-48e0-b49e-2b0d206c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.array([17775,79561])\n",
    "y_train = np.delete(y_train, indexes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a32780-2b57-4ca0-908d-069fe09bc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(np.array(X_train_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e6472-157b-4a0d-9abc-f0bd97118422",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca8912-e874-440d-a6d5-8008ca058dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6295b7-9d0a-47fa-b1d0-5bb638b5d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lemma(sentence):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    tokens = [tok.lemma_ for tok in nlp(sentence)]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59440b-c91d-444e-9f57-d6a099af272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_lemma('learn learned learning askg en espo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725efe7b-5e84-438d-abf2-3ce5d2844b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned_lemma = [preprocess_lemma(tweet) for tweet in X_train_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f74fa3-28a3-44e8-9011-d22222017fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(np.array(X_train_cleaned_lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae6491-72ba-4a27-b9e2-70ca0c505d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582ba67-9181-4602-a0d0-05d60ff90665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cleaned_lemma = [preprocess_lemma(tweet) for tweet in X_test_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3292518-0094-49d2-bf71-23a6f1909715",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = vectorizer.transform(np.array(X_test_cleaned_lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d5db9-1930-4610-972b-33985d9360be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416dc60-eaa5-4adb-aee7-739aef5494c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab21b720-c228-478a-b113-0b6561f12244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f4540-9540-48fa-901d-663c0654687f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf26cf7-00f5-4b17-9be0-ce6fd3b08147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d161d9-42dc-4151-af5a-9b26c7e60b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
